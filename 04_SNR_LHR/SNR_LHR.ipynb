{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ å¤„ç†æ–‡ä»¶å¤¹: D:\\Dataset\\Data_Watkins\\Best_WhiteBeaked_sounds (WhiteBeaked)\n",
      "\n",
      "ğŸ“‚ å¤„ç†æ–‡ä»¶å¤¹: D:\\Dataset\\Data_Watkins\\Best_AtlanticSpotted_sounds (AtlanticSpotted)\n",
      "\n",
      "ğŸ“‚ å¤„ç†æ–‡ä»¶å¤¹: D:\\Dataset\\Data_Watkins\\Best_WhiteSided_sounds (WhiteSided)\n",
      "\n",
      "ğŸ“Š æ•°æ®ç»Ÿè®¡ç»“æœï¼š\n",
      "\n",
      "ğŸ”¹ WhiteBeaked:\n",
      "   LHR > 1: 49  |  LHR < 1: 8\n",
      "   SNR 0-10: 10  |  SNR 10-20: 34\n",
      "   SNR 20-30: 13  |  SNR 30+: 0\n",
      "\n",
      "ğŸ”¹ AtlanticSpotted:\n",
      "   LHR > 1: 16  |  LHR < 1: 42\n",
      "   SNR 0-10: 33  |  SNR 10-20: 23\n",
      "   SNR 20-30: 2  |  SNR 30+: 0\n",
      "\n",
      "ğŸ”¹ WhiteSided:\n",
      "   LHR > 1: 36  |  LHR < 1: 19\n",
      "   SNR 0-10: 24  |  SNR 10-20: 30\n",
      "   SNR 20-30: 1  |  SNR 30+: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# å®šä¹‰æ–‡ä»¶å¤¹è·¯å¾„\n",
    "folders = {\n",
    "    \"WhiteBeaked\": r\"D:\\Dataset\\Data_Watkins\\Best_WhiteBeaked_sounds\",\n",
    "    \"AtlanticSpotted\": r\"D:\\Dataset\\Data_Watkins\\Best_AtlanticSpotted_sounds\",\n",
    "    \"WhiteSided\": r\"D:\\Dataset\\Data_Watkins\\Best_WhiteSided_sounds\"\n",
    "}\n",
    "\n",
    "def compute_snr_lhr_adaptive(signal, sample_rate):\n",
    "    \"\"\"\n",
    "    è®¡ç®— SNRï¼ˆä¿¡å™ªæ¯”ï¼‰å’Œ LHRï¼ˆä½é¢‘/é«˜é¢‘æ¯”ï¼‰\n",
    "    \"\"\"\n",
    "    # è®¡ç®—å‚…é‡Œå¶å˜æ¢\n",
    "    fft_signal = np.fft.fft(signal)\n",
    "    psd_signal = np.abs(fft_signal) ** 2  # è®¡ç®—åŠŸç‡è°±å¯†åº¦\n",
    "    freqs = np.fft.fftfreq(len(signal), d=1/sample_rate)\n",
    "    freqs = freqs[:len(freqs) // 2]\n",
    "    psd_signal = psd_signal[:len(psd_signal) // 2]\n",
    "\n",
    "    # --- è®¡ç®—èƒ½é‡ä¸­å¿ƒ ---\n",
    "    spectral_centroid = np.sum(freqs * psd_signal) / (np.sum(psd_signal) + 1e-8)\n",
    "\n",
    "    # --- è®¡ç®— SNR ---\n",
    "    geometric_mean = np.exp(np.mean(np.log(psd_signal + 1e-8)))  # é¿å… log(0)\n",
    "    arithmetic_mean = np.mean(psd_signal)\n",
    "    sfm = geometric_mean / (arithmetic_mean + 1e-8)\n",
    "    threshold = np.percentile(psd_signal, 90 * (1 - sfm))\n",
    "    signal_power = np.sum(psd_signal[psd_signal > threshold])\n",
    "    noise_power = np.sum(psd_signal[psd_signal <= threshold])\n",
    "    snr = 10 * np.log10(signal_power / (noise_power + 1e-8))\n",
    "\n",
    "    # --- è®¡ç®— LHR ---\n",
    "    low_freq_power = np.sum(psd_signal[freqs < spectral_centroid])\n",
    "    high_freq_power = np.sum(psd_signal[freqs >= spectral_centroid])\n",
    "    lhr = low_freq_power / (high_freq_power + 1e-8)\n",
    "\n",
    "    return snr, lhr\n",
    "\n",
    "# éå†æ¯ä¸ªæ–‡ä»¶å¤¹\n",
    "stats = {}\n",
    "\n",
    "for label, folder in folders.items():\n",
    "    print(f\"\\nğŸ“‚ å¤„ç†æ–‡ä»¶å¤¹: {folder} ({label})\")\n",
    "\n",
    "    # åˆå§‹åŒ–ç»Ÿè®¡è®¡æ•°\n",
    "    lhr_gt_1 = 0  # LHR > 1 çš„æ•°é‡\n",
    "    lhr_lt_1 = 0  # LHR < 1 çš„æ•°é‡\n",
    "    snr_bins = { \"0-10\": 0, \"10-20\": 0, \"20-30\": 0, \"30+\": 0 }  # SNR åˆ†å¸ƒ\n",
    "\n",
    "    # éå†æ–‡ä»¶å¤¹ä¸­çš„éŸ³é¢‘æ–‡ä»¶\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".wav\"):  # åªå¤„ç† WAV æ–‡ä»¶\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            # è¯»å–éŸ³é¢‘æ–‡ä»¶\n",
    "            signal, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # è®¡ç®— SNR å’Œ LHR\n",
    "            snr, lhr = compute_snr_lhr_adaptive(signal, sr)\n",
    "\n",
    "            # æ›´æ–° LHR è®¡æ•°\n",
    "            if lhr > 1:\n",
    "                lhr_gt_1 += 1\n",
    "            else:\n",
    "                lhr_lt_1 += 1\n",
    "\n",
    "            # æ›´æ–° SNR è®¡æ•°\n",
    "            if 0 <= snr < 10:\n",
    "                snr_bins[\"0-10\"] += 1\n",
    "            elif 10 <= snr < 20:\n",
    "                snr_bins[\"10-20\"] += 1\n",
    "            elif 20 <= snr < 30:\n",
    "                snr_bins[\"20-30\"] += 1\n",
    "            else:\n",
    "                snr_bins[\"30+\"] += 1\n",
    "\n",
    "    # å­˜å‚¨ç»Ÿè®¡ç»“æœ\n",
    "    stats[label] = {\n",
    "        \"LHR > 1\": lhr_gt_1,\n",
    "        \"LHR < 1\": lhr_lt_1,\n",
    "        \"SNR åˆ†å¸ƒ\": snr_bins\n",
    "    }\n",
    "\n",
    "# æ‰“å°ç»Ÿè®¡ç»“æœ\n",
    "print(\"\\nğŸ“Š æ•°æ®ç»Ÿè®¡ç»“æœï¼š\")\n",
    "for label, data in stats.items():\n",
    "    print(f\"\\nğŸ”¹ {label}:\")\n",
    "    print(f\"   LHR > 1: {data['LHR > 1']}  |  LHR < 1: {data['LHR < 1']}\")\n",
    "    print(f\"   SNR 0-10: {data['SNR åˆ†å¸ƒ']['0-10']}  |  SNR 10-20: {data['SNR åˆ†å¸ƒ']['10-20']}\")\n",
    "    print(f\"   SNR 20-30: {data['SNR åˆ†å¸ƒ']['20-30']}  |  SNR 30+: {data['SNR åˆ†å¸ƒ']['30+']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# å®šä¹‰æ–‡ä»¶å¤¹è·¯å¾„\n",
    "folder_1 = r\"D:\\Dataset\\Data_Watkins\\Best_WhiteBeaked_sounds\"\n",
    "folder_2 = r\"D:\\Dataset\\Data_Watkins\\Best_AtlanticSpotted_sounds\"\n",
    "folder_3 = r\"D:\\Dataset\\Data_Watkins\\Best_WhiteSided_sounds\"\n",
    "\n",
    "# ç›®æ ‡é‡‡æ ·ç‚¹æ•°\n",
    "target_length = 50000\n",
    "\n",
    "# å¤„ç†éŸ³é¢‘æ–‡ä»¶çš„å‡½æ•°\n",
    "def process_audio_files(folder):\n",
    "    processed_audios = []\n",
    "    audio_ids = []  # å­˜å‚¨æ–‡ä»¶ ID\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder, file)\n",
    "\n",
    "            # è¯»å–éŸ³é¢‘\n",
    "            audio, sr = librosa.load(file_path, sr=None)  # ä¿æŒåŸå§‹é‡‡æ ·ç‡\n",
    "            total_samples = len(audio)\n",
    "\n",
    "            # è®°å½•æ–‡ä»¶ IDï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰\n",
    "            file_id = os.path.splitext(file)[0]\n",
    "\n",
    "            # å¦‚æœéŸ³é¢‘é•¿åº¦ä¸è¶³ target_lengthï¼Œåˆ™å‰é¢è¡¥é›¶\n",
    "            if total_samples < target_length:\n",
    "                audio = np.pad(audio, (target_length - total_samples, 0), mode='constant')\n",
    "                processed_audios.append(audio)\n",
    "                audio_ids.append(file_id)  # è®°å½• ID\n",
    "            else:\n",
    "                # è®¡ç®—åº”åˆ‡åˆ†çš„æ®µæ•°\n",
    "                num_segments = max(1, round(total_samples / target_length))\n",
    "                segment_length = total_samples // num_segments\n",
    "\n",
    "                for i in range(num_segments):\n",
    "                    start = i * segment_length\n",
    "                    end = min(start + target_length, total_samples)  # ç¡®ä¿ä¸è¶Šç•Œ\n",
    "\n",
    "                    segment = audio[start:end]  # é»˜è®¤åˆ‡ç‰‡\n",
    "                    if len(segment) < target_length:\n",
    "                        segment = np.pad(segment, (0, target_length - len(segment)), mode='constant')  # ä¸è¶³æ—¶å¡«å……0\n",
    "\n",
    "                    processed_audios.append(segment)\n",
    "                    audio_ids.append(f\"{file_id}_seg{i}\")  # è®°å½•åˆ†å‰²åçš„ ID\n",
    "\n",
    "    return np.array(processed_audios), np.array(audio_ids)\n",
    "\n",
    "# å¤„ç†ä¸‰ä¸ªæ–‡ä»¶å¤¹\n",
    "data_whitebeaked, ids_whitebeaked = process_audio_files(folder_1)\n",
    "data_atlanticspotted, ids_atlanticspotted = process_audio_files(folder_2)\n",
    "data_whitesided, ids_whitesided = process_audio_files(folder_3)\n",
    "\n",
    "# å¯¹æ¯ä¸ªæ ·æœ¬å½’ä¸€åŒ–åˆ° [-1, 1]\n",
    "def normalize_audio(data):\n",
    "    return np.array([sample / np.max(np.abs(sample)) if np.max(np.abs(sample)) > 0 else sample for sample in data])\n",
    "\n",
    "data_whitebeaked = normalize_audio(data_whitebeaked)\n",
    "data_atlanticspotted = normalize_audio(data_atlanticspotted)\n",
    "data_whitesided = normalize_audio(data_whitesided)\n",
    "\n",
    "# ä¿å­˜éŸ³é¢‘æ•°æ®\n",
    "np.save(\"whitebeaked_sounds.npy\", data_whitebeaked)\n",
    "np.save(\"atlanticspotted_sounds.npy\", data_atlanticspotted)\n",
    "np.save(\"whitesided_sounds.npy\", data_whitesided)\n",
    "\n",
    "# ä¿å­˜éŸ³é¢‘ IDï¼ˆå¯é€‰æ‹©ä¿å­˜ä¸º .npy æˆ– .txtï¼‰\n",
    "np.save(\"whitebeaked_ids.npy\", ids_whitebeaked)\n",
    "np.save(\"atlanticspotted_ids.npy\", ids_atlanticspotted)\n",
    "np.save(\"whitesided_ids.npy\", ids_whitesided)\n",
    "\n",
    "# ä¹Ÿå¯ä»¥ä¿å­˜ä¸ºå¯è¯»çš„ .txt æ–‡ä»¶\n",
    "np.savetxt(\"whitebeaked_ids.txt\", ids_whitebeaked, fmt=\"%s\")\n",
    "np.savetxt(\"atlanticspotted_ids.txt\", ids_atlanticspotted, fmt=\"%s\")\n",
    "np.savetxt(\"whitesided_ids.txt\", ids_whitesided, fmt=\"%s\")\n",
    "\n",
    "# è¾“å‡ºæ•°ç»„å¤§å°\n",
    "print(f\"WhiteBeaked sounds shape: {data_whitebeaked.shape}, IDs: {ids_whitebeaked.shape}\")\n",
    "print(f\"AtlanticSpotted sounds shape: {data_atlanticspotted.shape}, IDs: {ids_atlanticspotted.shape}\")\n",
    "print(f\"WhiteSided sounds shape: {data_whitesided.shape}, IDs: {ids_whitesided.shape}\")\n",
    "\n",
    "print(\"å¤„ç†å®Œæˆï¼Œæ•°æ®åŠéŸ³é¢‘ ID å·²ä¿å­˜ã€‚\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TarRec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
